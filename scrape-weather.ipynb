{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Scraping\n",
    "\n",
    "The following document outlines how the weather data was collected for the project.\n",
    "I want to thank [Motor Sport Total](\"https://www.motorsport-total.com/\") for collecting this data during the various Grand Prix's. Without it, the weather data would have been far less accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'42'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import modules\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import os\n",
    "\n",
    "# Helper methods\n",
    "def convert_date(string):\n",
    "    return string\n",
    "\n",
    "def average(string):\n",
    "    \n",
    "    if \"-\" in string:\n",
    "        string = string.split(\"-\")\n",
    "        \n",
    "        if \"°\" in string[1]:\n",
    "            string[1] = string[1].replace(\"°\", \"\")\n",
    "        \n",
    "        avg = round((int(string[0]) + int(string[1]))/2)\n",
    "        return str(avg)\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "def average_air(string):\n",
    "    \n",
    "    if \".\" in string:\n",
    "        string = string.replace(\".\",\"\")\n",
    "    if \"-\" in string:\n",
    "        string = string.split(\"-\")\n",
    "        avg = round((int(string[0]) + int(string[1]))/2)\n",
    "        return str(avg)\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "def format_wind(string):\n",
    "    result = string.split('m/s')\n",
    "    \n",
    "    if ',' in result[0]:\n",
    "        result[0] = result[0].replace(',', '')\n",
    "    if ',' in result[1]:\n",
    "        result[1] = result[1].replace(',', '')\n",
    "    \n",
    "    speed = result[0].split()[0].strip()\n",
    "    direction = result[1].strip()\n",
    "    \n",
    "    if \"-\" in speed:\n",
    "        speed = average(speed)\n",
    "    \n",
    "    return [speed, direction]\n",
    "\n",
    "# Test function(s) 2,0-4,5 m/s, Nordwest\n",
    "average(\"35-48°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track information\n",
    "Here track information is placed that allows the function below to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track information that we want to scrape\n",
    "\n",
    "ital_url = [\"monza\", \"https://www.motorsport-total.com/formel-1/ergebnisse/\", \"\", \"/grosser-preis-von-italien/rennen\"]\n",
    "mont_url = [\"de-monaco\", \"https://www.motorsport-total.com/formel-1/ergebnisse/\", \"\", \"/grosser-preis-von-monaco/rennen\"]\n",
    "brit_url = [\"silverstone\", \"https://www.motorsport-total.com/formel-1/ergebnisse/\", \"\", \"/grosser-preis-von-grossbritannien/rennen\"]\n",
    "belg_url = [\"de-spa\", \"https://www.motorsport-total.com/formel-1/ergebnisse/\", \"\", \"/grosser-preis-von-belgien/rennen\"]\n",
    "braz_url = [\"interlagos\", \"https://www.motorsport-total.com/formel-1/ergebnisse/\", \"\", \"/grosser-preis-von-brasilien/rennen\"]\n",
    "hung_url = [\"hungaroring\", \"https://www.motorsport-total.com/formel-1/ergebnisse/\", \"\", \"/grosser-preis-von-ungarn/rennen\"]\n",
    "aust_url = [\"albert-park\", \"https://www.motorsport-total.com/formel-1/ergebnisse/\", \"\", \"/grosser-preis-von-australien/rennen\"]\n",
    "span_url = [\"catalunya\", \"https://www.motorsport-total.com/formel-1/ergebnisse/\", \"\", \"/grosser-preis-von-spanien/rennen\"]\n",
    "\n",
    "dates = ['2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'] \n",
    "#location_urls = [aust_url, brit_url, span_url, braz_url, belg_url, ital_url]\n",
    "location_urls = [ital_url, mont_url, brit_url, belg_url, braz_url, hung_url, aust_url, span_url]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Function\n",
    "The brains of the collection. Here, we convert the various urls and scrape information. Some data is modified in order to be more useful for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_weather():\n",
    "    # Create empty csv for writing\n",
    "    file = open('data/track_weather.csv', 'w', newline='')\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['track', 'date', 'local_time', 'weather', 'temp', 'track_temp', 'humidity', 'air_pressure', 'wind_speed', 'wind_direction'])\n",
    "    \n",
    "    for raw_url in location_urls:\n",
    "        track = raw_url[0]\n",
    "        print(\"INFO: NOW SCRAPING \" + raw_url[0])\n",
    "        \n",
    "        for year in dates:\n",
    "            # Create response & find raw weather data\n",
    "            raw_url[2] = year\n",
    "            url = raw_url[1] + raw_url[2] + raw_url[3]       \n",
    "            response = requests.get(url)\n",
    "            soup = bs(response.content, 'html.parser')\n",
    "            raw_weather = soup.find('div', {'id': 'session-info'}).find_all('td')\n",
    "\n",
    "            # Assign raw to actual variables\n",
    "            date = raw_weather[1].text.strip()\n",
    "            local_time = raw_weather[5].text.strip() + \":00\"\n",
    "            weather = raw_weather[13].text.strip()\n",
    "            temp = raw_weather[15].text.strip()[:-2]\n",
    "            track_temp = raw_weather[21].text.strip()[:-2]\n",
    "            humidity = raw_weather[17].text.strip()[:-1]\n",
    "            air_pressure = raw_weather[19].text.strip()[:-5]\n",
    "            wind = raw_weather[23].text.strip()\n",
    "\n",
    "            # Format particular data\n",
    "            temp = average(temp)\n",
    "            track_temp = average(track_temp)\n",
    "            humidity = average(humidity)\n",
    "            air_pressure = average_air(air_pressure)\n",
    "            wind_info = format_wind(wind)\n",
    "            wind_speed = wind_info[0]\n",
    "            wind_direction = wind_info[1]\n",
    "\n",
    "            # Write to file\n",
    "            writer.writerow([track, date, local_time, weather, temp, track_temp, humidity, air_pressure, wind_speed, wind_direction])\n",
    "            print(\"LOG: \" + year + \" FINISHED\")\n",
    "    \n",
    "    print(\"INFO: COMPLETED SCRAPING WEB DATA\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling Function\n",
    "Now the function is called, producing the data set used in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: NOW SCRAPING monza\n",
      "LOG: 2007 FINISHED\n",
      "LOG: 2008 FINISHED\n",
      "LOG: 2009 FINISHED\n",
      "LOG: 2010 FINISHED\n",
      "LOG: 2011 FINISHED\n",
      "LOG: 2012 FINISHED\n",
      "LOG: 2013 FINISHED\n",
      "LOG: 2014 FINISHED\n",
      "LOG: 2015 FINISHED\n",
      "LOG: 2016 FINISHED\n",
      "LOG: 2017 FINISHED\n",
      "LOG: 2018 FINISHED\n",
      "LOG: 2019 FINISHED\n",
      "INFO: NOW SCRAPING de-monaco\n",
      "LOG: 2007 FINISHED\n",
      "LOG: 2008 FINISHED\n",
      "LOG: 2009 FINISHED\n",
      "LOG: 2010 FINISHED\n",
      "LOG: 2011 FINISHED\n",
      "LOG: 2012 FINISHED\n",
      "LOG: 2013 FINISHED\n",
      "LOG: 2014 FINISHED\n",
      "LOG: 2015 FINISHED\n",
      "LOG: 2016 FINISHED\n",
      "LOG: 2017 FINISHED\n",
      "LOG: 2018 FINISHED\n",
      "LOG: 2019 FINISHED\n",
      "INFO: NOW SCRAPING silverstone\n",
      "LOG: 2007 FINISHED\n",
      "LOG: 2008 FINISHED\n",
      "LOG: 2009 FINISHED\n",
      "LOG: 2010 FINISHED\n",
      "LOG: 2011 FINISHED\n",
      "LOG: 2012 FINISHED\n",
      "LOG: 2013 FINISHED\n",
      "LOG: 2014 FINISHED\n",
      "LOG: 2015 FINISHED\n",
      "LOG: 2016 FINISHED\n",
      "LOG: 2017 FINISHED\n",
      "LOG: 2018 FINISHED\n",
      "LOG: 2019 FINISHED\n",
      "INFO: NOW SCRAPING de-spa\n",
      "LOG: 2007 FINISHED\n",
      "LOG: 2008 FINISHED\n",
      "LOG: 2009 FINISHED\n",
      "LOG: 2010 FINISHED\n",
      "LOG: 2011 FINISHED\n",
      "LOG: 2012 FINISHED\n",
      "LOG: 2013 FINISHED\n",
      "LOG: 2014 FINISHED\n",
      "LOG: 2015 FINISHED\n",
      "LOG: 2016 FINISHED\n",
      "LOG: 2017 FINISHED\n",
      "LOG: 2018 FINISHED\n",
      "LOG: 2019 FINISHED\n",
      "INFO: NOW SCRAPING interlagos\n",
      "LOG: 2007 FINISHED\n",
      "LOG: 2008 FINISHED\n",
      "LOG: 2009 FINISHED\n",
      "LOG: 2010 FINISHED\n",
      "LOG: 2011 FINISHED\n",
      "LOG: 2012 FINISHED\n",
      "LOG: 2013 FINISHED\n",
      "LOG: 2014 FINISHED\n",
      "LOG: 2015 FINISHED\n",
      "LOG: 2016 FINISHED\n",
      "LOG: 2017 FINISHED\n",
      "LOG: 2018 FINISHED\n",
      "LOG: 2019 FINISHED\n",
      "INFO: NOW SCRAPING hungaroring\n",
      "LOG: 2007 FINISHED\n",
      "LOG: 2008 FINISHED\n",
      "LOG: 2009 FINISHED\n",
      "LOG: 2010 FINISHED\n",
      "LOG: 2011 FINISHED\n",
      "LOG: 2012 FINISHED\n",
      "LOG: 2013 FINISHED\n",
      "LOG: 2014 FINISHED\n",
      "LOG: 2015 FINISHED\n",
      "LOG: 2016 FINISHED\n",
      "LOG: 2017 FINISHED\n",
      "LOG: 2018 FINISHED\n",
      "LOG: 2019 FINISHED\n",
      "INFO: NOW SCRAPING albert-park\n",
      "LOG: 2007 FINISHED\n",
      "LOG: 2008 FINISHED\n",
      "LOG: 2009 FINISHED\n",
      "LOG: 2010 FINISHED\n",
      "LOG: 2011 FINISHED\n",
      "LOG: 2012 FINISHED\n",
      "LOG: 2013 FINISHED\n",
      "LOG: 2014 FINISHED\n",
      "LOG: 2015 FINISHED\n",
      "LOG: 2016 FINISHED\n",
      "LOG: 2017 FINISHED\n",
      "LOG: 2018 FINISHED\n",
      "LOG: 2019 FINISHED\n",
      "INFO: NOW SCRAPING catalunya\n",
      "LOG: 2007 FINISHED\n",
      "LOG: 2008 FINISHED\n",
      "LOG: 2009 FINISHED\n",
      "LOG: 2010 FINISHED\n",
      "LOG: 2011 FINISHED\n",
      "LOG: 2012 FINISHED\n",
      "LOG: 2013 FINISHED\n",
      "LOG: 2014 FINISHED\n",
      "LOG: 2015 FINISHED\n",
      "LOG: 2016 FINISHED\n",
      "LOG: 2017 FINISHED\n",
      "LOG: 2018 FINISHED\n",
      "LOG: 2019 FINISHED\n",
      "INFO: COMPLETED SCRAPING WEB DATA\n"
     ]
    }
   ],
   "source": [
    "scrape_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
